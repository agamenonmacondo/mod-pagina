{
  "timestamp": "2025-05-30T01:30:03.961960",
  "topics": [
    {
      "title": "New report details China’s push to dominate artificial intelligence - SpaceNews",
      "keywords": [
        "report",
        "dominate",
        "artificial",
        "intelligence",
        "details"
      ],
      "relevance_score": 0.9,
      "category": "General",
      "full_content": {
        "success": true,
        "title": "New report details China’s push to dominate artificial intelligence - SpaceNews",
        "content": "WASHINGTON — China’s campaign to lead the world in artificial intelligence is being driven by a tightly coordinated effort between state and private sectors — and increasingly, that effort is reaching into space.\n\nA new report titled “China’s AI Infrastructure Surge,” released May 29 by the Special Competitive Studies Project and the intelligence firm Strider Technologies, describes a sweeping, state-led initiative to build out the physical backbone of AI dominance: massive data centers across the country, with plans that now stretch beyond Earth’s atmosphere.\n\nThe report says China has built or announced more than 250 AI-focused data centers nationwide. These facilities, packed with high-performance processors and immense power capacity, are the engine rooms for AI systems, handling the heavy computing loads required to train and run large-scale models. The Chinese government is coordinating this infrastructure expansion across national ministries and local authorities, according to the report, ensuring that AI development supports both economic and military goals.\n\n“The PRC is executing a state-directed campaign to dominate global artificial intelligence,” the report states, pointing to AI as a linchpin for China’s broader ambitions in tech leadership and military modernization.\n\nThe Special Competitive Studies Project is a non-profit group that supports U.S. long-term strategy in emerging technologies. Strider Technologies specializes in turning open-source information into security insights using AI.\n\nAs China builds out this infrastructure at home, it’s also preparing to deploy AI capabilities in orbit. Beijing is exploring the use of satellites equipped to function like data centers — capable of storing, processing and analyzing information in space. The aim is to move data processing closer to the point of collection, allowing satellites to make decisions autonomously and respond faster without having to send data back to Earth first.\n\nThe idea is gaining traction in both public and private sectors. Former Google CEO Eric Schmidt, now chief executive of space startup Relativity Space, has said he plans to deploy computing infrastructure in space as part of his vision for the future of AI.\n\nChina is already moving on this front. On May 14, the Chinese startup ADA Space and Zhejiang Lab launched the first 12 satellites of a planned supercomputing network of 2,800. These satellites are interconnected by high-speed laser links and aim to demonstrate the feasibility of shifting AI processing into orbit.\n\nChristopher Gragg, an intelligence analyst at Strider, said this space-based expansion is directly supported by the growing domestic data center network. “These investments are absolutely supporting those space efforts,” Gragg told reporters during a Defense Writers Group briefing.\n\nHe noted that the AI data centers are strategically clustered across China, often in regions tailored to specific industries. This, he said, allows for experimentation with other forms of remote data infrastructure, including deep-sea data centers.\n\nWashington has responded to China’s rapid AI buildout with export controls aimed at cutting off access to advanced semiconductors. In particular, the U.S. has restricted sales of Nvidia’s most powerful AI chips to China, citing concerns about their potential military applications. Both the Biden and Trump administrations have taken steps to prevent China from acquiring not only high-end chips, but also the tools and know-how to manufacture them.\n\nStill, analysts say these measures may not be enough to derail Beijing’s ambitions.\n\n“It is becoming increasingly clear that the traditional economic toolkit that we have in the U.S. government is not fit to the current reality of how businesses operate, how technology is diffused and how people move, or how ideas are shared,” Greg Levesque, CEO and co-founder of Strider Technologies, told the Defense Writers Group.\n\nHe said that while there are clear attempts to curb China’s technological rise, those efforts are also motivating China — and other nations — to get more innovative. “We need to have better and more dynamic intelligence monitoring of trade flows and where this technology is going,” he said. “We probably need to get away from slapping entities on lists and just simply making announcements that companies can’t do this anymore, because the ability to obfuscate ownership and create shell companies to still get at the underlying core technology is pervasive.”\n\nThe competition extends to human capital as well. Levesque said his firm has observed “a massive uptick in Chinese government recruitment of AI scientists in the United States” as part of Beijing’s broader AI strategy, while arguing that “the U.S. government has no real clear mission or strategy around mitigating that.”\n\nThe Trump administration has announced restrictions on visas for Chinese students seeking to study at U.S. universities, though Levesque suggested this reflects outdated thinking.\n\n“That’s a model and approach that is reflective of the current toolkit, and we need to get creative and imagine other ways to approach this,” he said, noting that this new report highlights the scale of the challenge facing U.S. policymakers as they seek to maintain America’s technological edge in an era of intensifying great power competition.\n\nSandra Erwin writes about military space programs, policy, technology and the industry that supports this sector. She has covered the military, the Pentagon, Congress and the defense industry for nearly two decades as editor of NDIA’s National Defense...\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tMore by Sandra Erwin",
        "images": [
          "https://i0.wp.com/spacenews.com/wp-content/uploads/2023/10/spacenews_logo.png?fit=792%2C216&quality=80&ssl=1"
        ],
        "url": "https://spacenews.com/new-report-details-chinas-push-to-dominate-artificial-intelligence/"
      }
    },
    {
      "title": "AI Turning Search Engines Into 'Yellow Pages' 05/29/2025 - MediaPost",
      "keywords": [
        "yellow",
        "forgot",
        "password",
        "engines",
        "search"
      ],
      "relevance_score": 0.8,
      "category": "General",
      "full_content": {
        "success": true,
        "title": "AI Turns Search Engines Into 'Yellow Pages' 05/29/2025",
        "content": "Subscribe today to gain access to every Research Intelligencer article we publish as well as the exclusive daily newsletter, full access to The MediaPost Cases, first-look research and daily insights from Joe Mandese, Editor in Chief.\n\nRemember when the Yellow Pages -- the massive,\nprinted book with local business names, addresses and telephone numbers -- was the primary resource for this information? Search engines are on their way to becoming this fossil, according to the CEO\nof a global digital marketing agency.\n\nGary Vaynerchuk, CEO at VaynerMedia, told Bloomberg TV: “We are in the early stages of the search engine looking like\nthe Yellow Pages.\"\n\nMany companies in the Fortune 5000 are in trouble, he said, because a huge percentage of their business relies on search. They managed to get their Lifetime Value to\nCustomer Acquisition Cost Ratio (LTV:CAC), and that’s what they use to drive intent.\n\nGoogle and others like Microsoft are trying to replace and update that search with AI to keep that\nbusiness. But companies, especially Google, will never again have the opportunity to control as much market share as search, he said.\n\nMany companies -- from Meta to OpenAI and Perplexity --\nwill replace what Google once had. AI will turn search into a fragmented ecosystem.\n\n\"People who have been lazy and overpaying for their brand value on search need to understand they are in\ntrouble and need to start creating demand, [as well as] learn how to win the SEO game in AI,\" he said. \"AI optimization is about to become a whole new game.\"\n\nArtificial intelligence (AI)\nengines still take information from the web, from places like Reddit. Some, but not all, have the ability to reason based on that web information.\n\nNoam Dorros, director analyst in the Gartner Marketing\npractice, believes CMOs should not abandon traditional search fundamentals.\n\n“CMOs and their teams should not get overexcited about one platform over another, and instead closely\nfollow the traffic and behavior patterns of their key customer segments, while creating budget and time to test new capabilities or opportunities in the broader\n\nSimilarweb, known for its web\ndata and analytics, on Wednesday launched Similarweb AI Agents, a suite of digital AI experts that let businesses change how they analyze AI SEO trends.\n\nThe agents are trained on the real-time\ndata from across 100 million websites, 4 million apps, 5 billion search keywords, and 20 million companies.\n\nEach agent is designed for a specific business function, from AI-based SEO and\ncontent planning, sales outreach, and trend discovery. The agent can correlate and summarize tremendous amounts of data faster and better than humans.\n\nOr Offer, CEO of Similarweb, wrote in a\nblog post that these agents are not another chatbot or generic assistants.\n\nThe launch is just the beginning. Additional agents under development for in the coming months include Shopper\nIntelligence; Stock Intelligence; Web Intelligence for competitive intelligence, share of voice, advertising insights; and Sales Intelligence to support lead generation.",
        "images": [
          "https://www.mediapost.com//googleads.g.doubleclick.net/pagead/viewthroughconversion/1071024836/?value=0&guid=ON&script=0"
        ],
        "url": "https://www.mediapost.com/publications/article/406235/ai-turning-search-engines-into-yellow-pages.html"
      }
    },
    {
      "title": "Improvement of metaphor understanding via a cognitive linguistic model based on hierarchical classification and artificial intelligence SVM - Nature",
      "keywords": [
        "improvement",
        "model",
        "metaphor",
        "based",
        "cognitive"
      ],
      "relevance_score": 0.7,
      "category": "General",
      "full_content": {
        "success": true,
        "title": "Improvement of metaphor understanding via a cognitive linguistic model based on hierarchical classification and artificial intelligence SVM | Scientific Reports",
        "content": "Scientific Reports volume 15, Article number: 18947 (2025) Cite this article This study aims to enhance computers’ ability to understand and generate metaphors, offering a novel perspective and technical approach in the field of natural language processing. It proposes a metaphor recognition algorithm that combines a Convolutional Neural Network (CNN) with a Support Vector Machine (SVM). First, the text is transformed into numerical features using a pre-trained word embedding model. Then, local contextual features are extracted through a multi-layer CNN. These features are subsequently input into the SVM for classification, enabling optimal metaphor recognition. In English verb metaphor recognition tasks, the model—when combined with the SVM classifier—achieves an accuracy of 85%, an F1 score of 85.5%, and a recall of 86%. In Chinese metaphor recognition experiments, the integration of the SVM classifier significantly improves performance, yielding an F1 score of 81.5%, an accuracy of 81%, and a recall of 82%. In conclusion, the proposed model effectively integrates the CNN’s powerful feature extraction capabilities with the SVM’s superior classification performance. Additionally, it incorporates part-of-speech features to enhance semantic analysis. This integrated approach enables more accurate identification of complex textual semantics, particularly in interpreting metaphorical language that requires deeper understanding. Metaphor understanding has long been a complex and challenging topic at the intersection of artificial intelligence (AI) and cognitive science. Cognitive linguistics, a discipline that integrates language with cognitive processes, emphasizes the influence of human thought patterns on language. Within this framework, metaphor is not merely a rhetorical device but a fundamental tool for human thought and cognition1,2,3. As an essential aspect of language expression, metaphor functions both as a linguistic embellishment and as a reflection of cognitive processes. By linking concepts across different domains, metaphors generate new meanings and help individuals convey thoughts and emotions more vividly and profoundly in communication4,5,6. Understanding metaphors requires more than interpreting literal meanings; it also involves deep reasoning and contextual interpretation, taking into account cultural background and personal experience. Despite advancements in natural language processing (NLP), computer systems continue to face significant challenges in accurately understanding and generating metaphors. Support Vector Machine (SVM), a powerful classification algorithm, has emerged as a valuable tool in the study of metaphor understanding due to its effectiveness in handling high-dimensional data and nonlinear classification problems7,8,9. While SVM is well-suited for linearly separable datasets, it can also manage nonlinear data by mapping it into a higher-dimensional space using kernel functions. SVMs offer high accuracy and generalization capabilities, enabling strong classification performance across a wide range of applications, including pattern recognition, image recognition, text classification, bioinformatics, and financial risk management. In classification tasks, SVM aims to maximize the decision boundary by identifying an optimal hyperplane that maximizes the minimum distance between the boundary and all sample points. This approach enhances classification robustness and reliability. This study aims to enhance computational metaphor comprehension and generation by integrating the classification capabilities of SVMs with the theoretical framework of cognitive linguistics. Based on the characteristics of metaphor, an SVM-based classification model is developed. Feature vectors are constructed and selected to transform metaphorical text representations into numerical form, which is then input into the SVM model for classification. Additionally, parameter optimization techniques are employed to improve the model’s classification performance and generalization ability. At the theoretical level, a metaphor recognition mechanism is established. At the processing level, the classification capabilities of SVM are applied to process metaphors in real time. At the neurological level, the study incorporates findings from neuroscience to explore the neural mechanisms underlying metaphor comprehension. The Convolutional Neural Network + Support Vector Machine (CNN + SVM) hybrid model proposed in this study effectively combines the automatic text feature extraction capabilities of CNNs with the robust classification performance of SVMs in handling high-dimensional and nonlinear tasks. CNNs are particularly effective in capturing multi-level semantic information, while SVMs excel in managing complex classification scenarios. This ensemble approach significantly improves accuracy in identifying complex semantic patterns, particularly in tasks that demand deep semantic understanding, such as metaphor recognition. The cognitive language model is an AI technology designed to understand and generate language by mimicking the way the human brain processes linguistic information. With the advancement of deep learning (DL), particularly the application of machine learning (ML) algorithms, cognitive language models have made significant progress in areas such as semantic analysis and emotion recognition10,11,12. Zlate et al. (2021)13 proposed a neural network-based cognitive language model specifically developed to handle metaphorical language expressions. Their study demonstrated that the model could effectively capture the multi-dimensional features of metaphors by training on large-scale language datasets, thereby improving metaphor recognition accuracy. Lin (2021)14 investigated the role of contextual information in enhancing machine comprehension of metaphors, employing an improved SVM-based method that integrated contextual features to detect metaphors more effectively. Pellert et al. (2024)15 examined the influence of cultural factors on metaphor understanding. By comparing metaphor expressions across different cultural contexts, the study introduced a cross-cultural cognitive language model framework, emphasizing the importance of cultural considerations in metaphor processing. Basiri et al. (2021)16 proposed a cognitive language model based on Recurrent Neural Networks (RNNs), specifically designed to capture long-distance dependencies within sentences. Their research showed that, compared to traditional feedforward neural networks, the RNN-based model more accurately simulated the brain’s memory mechanisms in language processing, thereby enhancing its ability to understand complex syntactic structures. Ong et al. (2024)17 focused on cognitive language model representation in multilingual environments. By comparing models trained on datasets from multiple languages, they highlighted how structural and semantic differences across languages often hinder direct model transfer. To address this challenge, the researchers proposed a meta-learning-based approach that enables the model to adapt rapidly to new languages while maintaining strong performance in its original language setting. This approach offers a promising direction for developing more generalizable cognitive language models. Soydaner (2022)18 explored the integration of attention mechanisms into cognitive language models and designed a framework incorporating a multi-layer attention mechanism. This method allowed the system to dynamically focus on the most critical parts of the input, thereby improving processing accuracy and efficiency. Elkenawy et al.19 highlighted the advantages of using ML techniques, including optimizers and ensemble regression models, to achieve promising results in classification and regression tasks. Alkhammash et al.20 stated that normalization is a technique for independently scaling input values, aiming to transform the mean to zero and the standard deviation to one. Tarek et al.21 argued that mathematical optimization involves the numerical computation of system parameters to make decisions based on unseen data, and is a fundamental principle of ML. Elshewey et al.22 asserted that feature selection reduces the cost and time required to train models. By minimizing the number of features, computational resources needed for training, testing, and deployment are also reduced. Alzakari et al.23 proposed a CNN-LSTM-based model for potato disease detection, further confirming that the accuracy and generalization ability of SVM enable it to achieve strong classification results across various datasets. Directly transferring existing models to new linguistic environments is not always optimal. To address this challenge, this study proposes a meta-learning-based approach that allows the model to quickly adapt to new linguistic contexts without compromising its strong performance in the original language setting. In conclusion, cognitive language models have demonstrated significant capabilities across various aspects of language processing. However, considerable challenges remain in achieving comprehensive linguistic understanding, particularly when modeling complex phenomena like metaphor and overcoming cross-linguistic barriers. This study aims to develop an AI SVM-based hierarchical classification cognitive language model, with a focus on the complex language phenomenon of metaphor understanding. A multi-level classification system is constructed to capture the subtle differences in metaphors more precisely. Compared to using CNN or SVM individually, the combined model designed in this study achieves more accurate metaphor recognition by integrating the powerful feature extraction capabilities of CNN with the strengths of SVM in handling high-dimensional data and nonlinear classification problems. CNN automatically extracts multi-level semantic information from the text, while SVM optimizes classification performance by identifying the optimal decision boundary when processing the complex features extracted by CNN, thereby enhancing classification accuracy. The core principle of cognitive metaphor theory lies in the systematic and subconscious nature of metaphors. According to this theory, metaphor is not an isolated or incidental linguistic phenomenon but rather a fundamental element of human thinking and the language system. The use of metaphor is a subconscious cognitive process, meaning individuals are often unaware of the underlying cognitive mechanisms when employing metaphors. As a complex linguistic phenomenon, the automatic recognition and understanding of metaphors has always been a key research direction in NLP. Designing an effective method for metaphor recognition and understanding requires a comprehensive approach that considers multiple factors, including but not limited to contextual information, emotional analysis, cross-language adaptability, and cultural differences. NLP technology encompasses part-of-speech (POS) tagging, syntactic analysis, and semantic understanding. POS tagging helps the system identify the lexical categories in the text, while syntactic analysis reveals the structural relationships between sentence components. Meanwhile, semantic understanding provides insight into the true intention of users through contextual inference... [Contenido truncado]",
        "images": [
          "https://media.springernature.com/full/nature-cms/uploads/product/srep/header-d3c533c187c710c1bedbd8e293815d5f.svg"
        ],
        "url": "https://www.nature.com/articles/s41598-025-04171-5"
      }
    }
  ]
}