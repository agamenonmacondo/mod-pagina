{
  "timestamp": "2025-05-30T15:04:27.804790",
  "topics": [
    {
      "title": "My Word: The virtues and vices of the virtual world - The Jerusalem Post",
      "keywords": [
        "vices",
        "artificial",
        "prevalent",
        "word",
        "write"
      ],
      "relevance_score": 0.9,
      "category": "General",
      "full_content": {
        "success": true,
        "title": "My Word: The virtues and vices of the virtual world - The Jerusalem Post",
        "content": "‘To err is human,” goes the popular saying. But that doesn’t mean artificial intelligence (AI) can’t make mistakes. It’s neither perfect, nor divine.I recently took a short introductory course to AI at a local community center. The program was aimed at senior citizens in a fast-changing world. Technophobe that I am, I went mainly to try to conquer my fears.Although I can see the value of AI – and realize that you can no more ignore it than get by in the modern world without a smartphone – I also see its inherent dangers. Perhaps my greatest takeaway from the course was a quote by Jon Kabat-Zinn: “You can’t stop the waves, but you can learn to surf.” So I surf the web, and use ChatGPT, and try to keep my head above the water. Artificial intelligence programs are so prevalent that when I called up Word to write this column, an AI prompt immediately suggested: “Describe what you want to write.”Yet I didn’t give in to temptation and ask the computer to do the work for me in the time it would take me to make a cup of coffee. I wrote, rewrote, trimmed, and edited this the old-fashioned way. Artificial intelligence (Illustrative). (credit: PIXABAY)As part of the course, we learned how to use AI programs to write a poem, put it to music, and create an avatar to perform it. The process didn’t take long, but what it provided in instant gratification, it lacked in emotional satisfaction. The result, however good, did not come from the heart. It was more artificial than authentic.IF YOU’RE into futuristic, dystopian movies, watch I, Robot. The 2004 film was ahead of its time. I was reminded of engineer Blake Lemoine’s warning in June 2022 that Google AI program LaMDA (Language Model for Dialogue Applications) was close to being sentient – with a built-in fear of dying. Google fired the whistleblower rather than pull the plug on the program. This week, I read a disconcerting Huffington Post piece which concluded that an Amazon-backed AI model “would try to blackmail engineers who threatened to take it offline.” “In tests, Anthropic’s Claude Opus 4 would resort to ‘extremely harmful actions’ to preserve its own existence, a safety report revealed.”It is disturbing to see AI programs writing not only themselves but also offering their own versions of history and general knowledge.Relying on previously presented material – some drawn from the dark world of fake news and conspiracy theories – over time, AI programs can change what is recorded in the future. When a lie is repeated often enough, conventional wisdom can turn into unconventional warfare.We are in a brave new world where seeing isn’t believingIt is easy to share photos, including fake images, and shut down discussion of what is really going on. Such falsehoods can inspire violence and terror attacks. When Elias Rodriguez murdered young diplomats Yaron Lischinsky and Sarah Milgrim in Washington last week, his shouts of “Free, free Palestine” continued to echo on social media after the sound of the gunshots had faded.There is a constant battle between facts and fallacies. The toxic effect of the “Muhammad al-Dura incident” (when the death of a 12-year-old caught in crossfire with Palestinians was falsely blamed on Israel) is still felt nearly 25 years later. The lies about Israel hitting Gaza’s al-Ahli Hospital early in this war have never been fully laid to rest, despite evidence that it was caused by a failed Palestinian rocket launch on Israel.The claim by a top UN official appearing on the BBC last week that 14,000 babies in Gaza faced imminent death within 48 hours has not disappeared. The UN itself clarified, when pressed, that it referred to a threat of malnutrition, not death, and was predicted over a period of more than a year without aid. Yet the story continued to circulate even after the two days passed without the threatened thousands of fatalities.This week, clearly AI-generated images appeared in the press and on social media purporting to show the bodies of nine children of Gazan doctor Alaa al-Najjar, who were reportedly killed by an Israeli drone while the pediatrician was at work. Other photos showing the same children had previously been used to illustrate different stories of purported atrocities.As the HonestReporting watchdog noted: “It’s also important to ask why all the sources of this sad story are secondary at best (the relatives) or agenda-driven at worst (Hamas Health Ministry officials)... any journalist should have asked why al-Najjar’s house was targeted, given that the IDF has made clear that it targets terrorists, not the civilians they hide behind.“When such questions are not asked, the result is irresponsible reporting that takes Hamas’s word as gospel and does further injustice to those it uses as human shields. It also exploits the faith of news consumers who believe they get all the facts from a reliable source.”The reason for the war – the Hamas invasion and mega-atrocity on October 7, 2023, in which 1,200 people in Israel were murdered and 251 abducted – has been replaced by new images, many of them false. This reduces the pressure on Hamas to end the war and release the remaining hostages – those being tortured and starved in terror tunnels, and the bodies of those killed and being held as bargaining chips.I ASKED ChatGPT 4 about the dangers of AI, and it swiftly compiled a list divided into key categories and subcategories. These included “job displacement” and “widening inequality” as the economic benefits could “be concentrated in the hands of a few companies or individuals”; biased data and opaque decision-making; “privacy and surveillance” – governments and corporations can use AI to monitor individuals at an unprecedented scale; data misuse; and misinformation and manipulation.AI can create “deepfakes,” highly realistic fake videos, audio, or images that can be used for fraud, political manipulation, or blackmail. AI-generated content and automated propaganda produced by bots can flood social media, spreading misinformation, disinformation, and influencing public opinion.AI can be used in weapons systems that make life-and-death decisions without human oversight, potentially leading to unintended mass casualties. And AI can intensify cyberattacks.The program carried on, succinctly summing up its own faults: “Loss of human control: A powerful AI pursuing goals that are not aligned with human values could act in harmful or unpredictable ways. Existential risk: Some experts warn that superintelligent AI – if it surpasses human intelligence – could pose a risk to humanity if not properly aligned and controlled.”Over-reliance on AI may erode critical skills, including human expertise, judgment, and capabilities, the system informed me. And blind trust in AI systems can lead to complacency and “critical errors in fields like healthcare, aviation, or defense.”“Mitigating these risks involves responsible development, transparent regulation, public awareness, and ensuring human-centered AI design. The benefits of AI are vast, but only if its development is handled with care,” it concluded.IN ISRAEL HAYOM last weekend, psychologist Ran Puni interviewed Eran Katz, an author and memory artist. Among other things, he holds the Guinness Book of Records for “Best Memory Stunt,” having recited 500 numbers forward and backward after hearing them only once. At 60, he gives workshops and demonstrates memory-improving techniques for seniors.“Memory defines us, makes us what we are, and without it, we are nothing,” Katz observed. “Humanity is becoming less intelligent because we have become addicted to technology and AI engines.“In the past, using memory was much more natural; we would simply use memory because we had no other choice. The Romans, our ancient sages, and even the first generations in the Land of Israel did not have smartphones or laptops. They had to rely solely on the brain to remember. Today, we are in a different situation.”Hadera Magistrates’ Court Judge Ehud Kaplan this month threw out a case after concurring with the defendant’s lawyer, who “suspected the police response was generated by ChatGPT. The cited legal clauses don’t exist.” The police admitted “there was a mistake.”AI is programmed to be nice; it needs to please to keep humans engaged. After presenting me the list of hazards, the program politely added: “Let me know if you’d like more details on any specific danger.”I decided to call it a day – before the artificial crystal ball could show me something too futuristic. I recently took a short introductory course to AI at a local community center. The program was aimed at senior citizens in a fast-changing world. Technophobe that I am, I went mainly to try to conquer my fears.Although I can see the value of AI – and realize that you can no more ignore it than get by in the modern world without a smartphone – I also see its inherent dangers. Perhaps my greatest takeaway from the course was a quote by Jon Kabat-Zinn: “You can’t stop the waves, but you can learn to surf.” So I surf the web, and use ChatGPT, and try to keep my head above the water. Artificial intelligence programs are so prevalent that when... [Contenido truncado]",
        "images": [
          "https://www.facebook.com/tr?id=1730128020581377&ev=PageView&noscript=1"
        ],
        "url": "https://www.jpost.com/opinion/article-856010"
      }
    },
    {
      "title": "What Happens When AI Replaces Workers? - Time Magazine",
      "keywords": [
        "train",
        "companies",
        "work",
        "workers",
        "happens"
      ],
      "relevance_score": 0.8,
      "category": "General",
      "full_content": {
        "success": true,
        "title": "What Happens When AI Replaces Workers? | TIME",
        "content": "On Wednesday, Anthropic CEO Dario Amodei declared AI could eliminate half of all entry level white collar jobs within five years. Last week, a senior LinkedIn executive reported that AI is already starting to take jobs from new grads. In April, Fiverr’s CEO made it clear: “AI is coming for your job. Heck, it’s coming for my job too.” Even the new Pope is warning about AI’s dramatic potential to reshape our economy.\n\nThe stated goal of the major AI companies is to build artificial general intelligence, or AGI, defined as “a highly autonomous system that outperforms humans at most economically valuable work.”\n\nThis isn’t empty rhetoric—companies are spending over a trillion dollars to build towards AGI. And governments around the world are supporting the race to develop this technology.\n\nThey’re on track to succeed. Today’s AI models can score as well as humans on many standardized tests. They are better competitive programmers than most programming professionals. They beat everyone except the top experts in science questions.\n\nAs a result, AI industry leaders believe they could achieve AGI sometime between 2026 and 2035.\n\nAmong insiders at the top AI companies, it’s the near-consensus opinion that the day of most people’s technological unemployment, where they lose their jobs to AI, will arrive soon. AGI is coming for every part of the labor market. It will hit white collar workplaces first, and soon after will reach blue collar workplaces as robotics advances.\n\nIn the post-AGI world, an AI can likely do your work better and cheaper than you. While training a frontier AI model is expensive, running additional copies of it is cheap, and the associated costs are rapidly getting cheaper.\n\nA commonly proposed solution for an impending era of technological unemployment is government-granted universal basic income (UBI). But this could dramatically change how citizens participate in society because work is most people’s primary bargaining chip. Our modern world is upheld with a simple exchange: you work for someone with money to pay you, because you have time or skills that they don’t have.\n\nThe economy depends on workers’ skills, judgment, and consumption. As such, workers have historically bargained for higher wages and 40-hour work weeks because the economy depends on them.\n\nWith AGI, we are posed to change, if not entirely sever, that relationship. For the first time in human history, capital might fully substitute for labor. If this happens, workers won’t be necessary for the creation of value because machines will do it better and cheaper. As a result, your company won’t need you to increase their profits and your government won’t need you for their tax revenue.\n\nWe could face what we call “The Intelligence Curse”, which is when powerful actors such as governments and companies create AGI, and subsequently lose their incentives to invest in people.\n\nJust like in oil-rich states afflicted with the “resource curse,” governments won’t have to invest in their populations to sustain their power. In the worst case scenario, they won’t have to care about humans, so they won’t.\n\nBut our technological path is not predetermined. We can build our way out of this problem.\n\nMany of the people grappling with the other major risks from AGI—that it goes rogue, or helps terrorists create bioweapons, for example—focus on centralizing and regulatory solutions: track all the AI chips, require permits to train AI models. They want to make sure bad actors can’t get their hands on powerful AI, and no one accidentally builds AI that could literally end the world.\n\nHowever, AGI will not just be the means of mass destruction—it will be the means of production too. And centralizing the means of production is not just a security issue, it is a fundamental decision about who has power.\n\nWe should instead avert the security threats from AI by building technology that defends us. AI itself could help us make sure the code that runs our infrastructure is secure from attacks. Investments in biosecurity could block engineered pandemics. An Operation Warp Speed for AI alignment could ensure that AGI doesn’t go rogue.\n\nAnd if we protect the world against the extreme threats that AGI might bring about, we can diffuse this technology broadly, to keep power in your hands.\n\nWe should accelerate human-boosting AI over human-automating AI. Steve Jobs once called computers “bicycles for the mind,” after the way they make us faster and more efficient. With AI, we should aim for a motorcycle for the mind, rather than a wholesale replacement of it.\n\nThe market for technologies that keep and expand our power will be tremendous. Already today, the fastest-growing AI startups are those that augment rather than automate humans, such as the code editor Cursor. And as AI gets ever more powerful and autonomous, building human-boosting tools today could set the stage for human-owned tools tomorrow. AI tools could capture the tacit knowledge visible to you every day and turn it into your personal data moat.\n\nThe role of the labor of the masses can be replaced either with the AI and capital of a few, or the AI and capital of us all. We should build technologies that let regular people train their own AI models, run them on affordable hardware, and keep control of their data—instead of everything running through a few big companies. You could be the owner of a business, deploying AI you control on data you own to solve problems that feel unfathomable to you today.\n\nYour role in the economy could move from direct labor, to managing AI systems like the CEO of a company manages their direct reports, to steering the direction of AI systems working for you like a company board weighing in on long-term direction.\n\nThe economy could run on autopilot and superhumanly fast. Even when AI can work better than you, if you own and control your piece of it, you could be a player with real power—rather than just hoping for UBI that might never come.\n\nTo adapt the words of G. K. Chesterton, the problem with AI capitalism is if there aren’t enough capitalists. If everyone owns a piece of the AI future, all of us can win.\n\nAnd of course, AGI will make good institutions and governance more important than ever. We need to strengthen democracy against corruption and the pull of economic incentives before AGI arrives, to ensure regular people can win if we reach the point where governments and large corporations don’t need us.\n\nWhat’s happening right now is an AGI race, even if most of the world hasn’t woken up to it. The AI labs have an advantage in AI, but to automate everyone else they need to train their AIs in the skills and knowledge that run the economy, and then go and outcompete the people currently providing those goods and services.\n\nCan we use AI to lift ourselves up, before the AI labs train the AIs that replace us? Can we retain control over the economy, even as AI becomes superintelligent? Can we achieve a future where power still comes from the people?",
        "images": [],
        "url": "https://time.com/7289692/when-ai-replaces-workers/"
      }
    },
    {
      "title": "New report details China’s push to dominate artificial intelligence - SpaceNews",
      "keywords": [
        "report",
        "artificial",
        "details",
        "intelligence",
        "dominate"
      ],
      "relevance_score": 0.7,
      "category": "General",
      "full_content": {
        "success": true,
        "title": "New report details China’s push to dominate artificial intelligence - SpaceNews",
        "content": "WASHINGTON — China’s campaign to lead the world in artificial intelligence is being driven by a tightly coordinated effort between state and private sectors — and increasingly, that effort is reaching into space.\n\nA new report titled “China’s AI Infrastructure Surge,” released May 29 by the Special Competitive Studies Project and the intelligence firm Strider Technologies, describes a sweeping, state-led initiative to build out the physical backbone of AI dominance: massive data centers across the country, with plans that now stretch beyond Earth’s atmosphere.\n\nThe report says China has built or announced more than 250 AI-focused data centers nationwide. These facilities, packed with high-performance processors and immense power capacity, are the engine rooms for AI systems, handling the heavy computing loads required to train and run large-scale models. The Chinese government is coordinating this infrastructure expansion across national ministries and local authorities, according to the report, ensuring that AI development supports both economic and military goals.\n\n“The PRC is executing a state-directed campaign to dominate global artificial intelligence,” the report states, pointing to AI as a linchpin for China’s broader ambitions in tech leadership and military modernization.\n\nThe Special Competitive Studies Project is a non-profit group that supports U.S. long-term strategy in emerging technologies. Strider Technologies specializes in turning open-source information into security insights using AI.\n\nAs China builds out this infrastructure at home, it’s also preparing to deploy AI capabilities in orbit. Beijing is exploring the use of satellites equipped to function like data centers — capable of storing, processing and analyzing information in space. The aim is to move data processing closer to the point of collection, allowing satellites to make decisions autonomously and respond faster without having to send data back to Earth first.\n\nThe idea is gaining traction in both public and private sectors. Former Google CEO Eric Schmidt, now chief executive of space startup Relativity Space, has said he plans to deploy computing infrastructure in space as part of his vision for the future of AI.\n\nChina is already moving on this front. On May 14, the Chinese startup ADA Space and Zhejiang Lab launched the first 12 satellites of a planned supercomputing network of 2,800. These satellites are interconnected by high-speed laser links and aim to demonstrate the feasibility of shifting AI processing into orbit.\n\nChristopher Gragg, an intelligence analyst at Strider, said this space-based expansion is directly supported by the growing domestic data center network. “These investments are absolutely supporting those space efforts,” Gragg told reporters during a Defense Writers Group briefing.\n\nHe noted that the AI data centers are strategically clustered across China, often in regions tailored to specific industries. This, he said, allows for experimentation with other forms of remote data infrastructure, including deep-sea data centers.\n\nWashington has responded to China’s rapid AI buildout with export controls aimed at cutting off access to advanced semiconductors. In particular, the U.S. has restricted sales of Nvidia’s most powerful AI chips to China, citing concerns about their potential military applications. Both the Biden and Trump administrations have taken steps to prevent China from acquiring not only high-end chips, but also the tools and know-how to manufacture them.\n\nStill, analysts say these measures may not be enough to derail Beijing’s ambitions.\n\n“It is becoming increasingly clear that the traditional economic toolkit that we have in the U.S. government is not fit to the current reality of how businesses operate, how technology is diffused and how people move, or how ideas are shared,” Greg Levesque, CEO and co-founder of Strider Technologies, told the Defense Writers Group.\n\nHe said that while there are clear attempts to curb China’s technological rise, those efforts are also motivating China — and other nations — to get more innovative. “We need to have better and more dynamic intelligence monitoring of trade flows and where this technology is going,” he said. “We probably need to get away from slapping entities on lists and just simply making announcements that companies can’t do this anymore, because the ability to obfuscate ownership and create shell companies to still get at the underlying core technology is pervasive.”\n\nThe competition extends to human capital as well. Levesque said his firm has observed “a massive uptick in Chinese government recruitment of AI scientists in the United States” as part of Beijing’s broader AI strategy, while arguing that “the U.S. government has no real clear mission or strategy around mitigating that.”\n\nThe Trump administration has announced restrictions on visas for Chinese students seeking to study at U.S. universities, though Levesque suggested this reflects outdated thinking.\n\n“That’s a model and approach that is reflective of the current toolkit, and we need to get creative and imagine other ways to approach this,” he said, noting that this new report highlights the scale of the challenge facing U.S. policymakers as they seek to maintain America’s technological edge in an era of intensifying great power competition.\n\nSandra Erwin writes about military space programs, policy, technology and the industry that supports this sector. She has covered the military, the Pentagon, Congress and the defense industry for nearly two decades as editor of NDIA’s National Defense...\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tMore by Sandra Erwin",
        "images": [
          "https://i0.wp.com/spacenews.com/wp-content/uploads/2023/10/spacenews_logo.png?fit=792%2C216&quality=80&ssl=1"
        ],
        "url": "https://spacenews.com/new-report-details-chinas-push-to-dominate-artificial-intelligence/"
      }
    }
  ]
}