from flask import Blueprint, render_template, jsonify, current_app, send_from_directory, redirect, url_for, abort
from datetime import datetime, timedelta
from pathlib import Path
import threading
import logging
import json
import subprocess
import time
import os
import sys  # ‚úÖ AGREGAR IMPORT FALTANTE

logger = logging.getLogger(__name__)
news_bp = Blueprint('news', __name__)

# Variables globales para control del flujo SEO
last_seo_execution = None  # ‚úÖ NOMBRE CORRECTO
seo_execution_interval = timedelta(hours=12)  # 2 veces al d√≠a
seo_lock = threading.Lock()

# ‚úÖ VARIABLE PARA CONTROLAR EJECUCI√ìN AUTOM√ÅTICA
auto_seo_enabled = True
last_check_time = None

def get_seo_paths():
    """Obtener rutas del sistema SEO"""
    base_dir = Path(__file__).parent.parent
    seo_dir = base_dir / 'llmpagina' / 'ava_seo'
    
    return {
        'workflow_script': seo_dir / 'seo_workflow.py',
        'output_dir': seo_dir / 'output',
        'articulos_dir': seo_dir / 'output' / 'articulos',
        'seo_json_dir': seo_dir / 'output' / 'seo_json',
        'static_dir': seo_dir / 'output' / 'static',
        'results_dir': seo_dir / 'results',
        'latest_articles': seo_dir / 'results' / 'latest_articles.json',
        'latest_results': seo_dir / 'results' / 'latest_results.json'
    }

def create_default_image():
    """Crear imagen por defecto si no existe"""
    try:
        static_images_dir = Path(__file__).parent.parent / 'llmpagina' / 'static' / 'images'
        static_images_dir.mkdir(parents=True, exist_ok=True)
        
        default_image_path = static_images_dir / 'default-article.png'
        
        if not default_image_path.exists():
            try:
                from PIL import Image, ImageDraw, ImageFont
                
                img = Image.new('RGB', (600, 400), color='#1c1c1c')
                draw = ImageDraw.Draw(img)
                
                try:
                    font = ImageFont.truetype("arial.ttf", 40)
                except:
                    font = ImageFont.load_default()
                
                text1 = "AVA"
                bbox1 = draw.textbbox((0, 0), text1, font=font)
                text1_width = bbox1[2] - bbox1[0]
                x1 = (600 - text1_width) // 2
                y1 = 150
                draw.text((x1, y1), text1, fill='#FFD700', font=font)
                
                try:
                    font2 = ImageFont.truetype("arial.ttf", 24)
                except:
                    font2 = ImageFont.load_default()
                
                text2 = "Art√≠culo de IA"
                bbox2 = draw.textbbox((0, 0), text2, font=font2)
                text2_width = bbox2[2] - bbox2[0]
                x2 = (600 - text2_width) // 2
                y2 = 220
                draw.text((x2, y2), text2, fill='#FFD700', font=font2)
                
                img.save(default_image_path)
                logger.info(f"‚úÖ Imagen PNG por defecto creada: {default_image_path}")
                
            except ImportError:
                create_basic_png_fallback()
            except Exception as e:
                logger.error(f"Error creando imagen PNG: {e}")
                create_basic_png_fallback()
        
    except Exception as e:
        logger.error(f"Error en create_default_image: {e}")

def create_basic_png_fallback():
    """Crear PNG b√°sico sin librer√≠as externas"""
    try:
        static_images_dir = Path(__file__).parent.parent / 'llmpagina' / 'static' / 'images'
        static_images_dir.mkdir(parents=True, exist_ok=True)
        default_image_path = static_images_dir / 'default-article.png'
        
        if not default_image_path.exists():
            png_data = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x06\x00\x00\x00\x1f\x15\xc4\x89\x00\x00\x00\rIDATx\x9cc\xf8\x0f\x00\x00\x01\x00\x01\x00\x18\xdd\x8d\xb4\x00\x00\x00\x00IEND\xaeB`\x82'
            
            with open(default_image_path, 'wb') as f:
                f.write(png_data)
                
            logger.info(f"‚úÖ PNG b√°sico creado: {default_image_path}")
            
    except Exception as e:
        logger.error(f"Error creando PNG b√°sico: {e}")

def find_corresponding_image(article_data, static_dir, app_context=None):
    """Buscar imagen correspondiente al art√≠culo espec√≠fico"""
    try:
        article_title = article_data.get('title', '')
        run_id = article_data.get('run_id', '')
        filename = article_data.get('filename', '')
        
        logger.info(f"üîç Buscando imagen para:")
        logger.info(f"   üìù T√≠tulo: {article_title}")
        logger.info(f"   üÜî Run ID: {run_id}")
        logger.info(f"   üìÑ Filename: {filename}")
        
        if not static_dir.exists():
            logger.warning(f"‚ö†Ô∏è Directorio no existe: {static_dir}")
            return get_fallback_image(article_title, app_context)
        
        # M√âTODO 1: Buscar por archivo de metadata espec√≠fico
        image_from_metadata = find_image_by_metadata_safe(article_data, static_dir)
        if image_from_metadata and image_from_metadata.get('exists'):
            logger.info(f"‚úÖ Imagen encontrada por metadata: {image_from_metadata.get('filename', 'N/A')}")
            return build_image_response(image_from_metadata, article_title, 'metadata_title', app_context)
        
        # M√âTODO 2: Buscar por run_id
        if run_id:
            image_from_run_id = find_image_by_run_id_safe(run_id, static_dir)
            if image_from_run_id and image_from_run_id.get('exists'):
                logger.info(f"‚úÖ Imagen encontrada por run_id: {image_from_run_id.get('filename', 'N/A')}")
                return build_image_response(image_from_run_id, article_title, 'run_id', app_context)
        
        # M√âTODO 3: Buscar por t√≠tulo
        image_from_title = find_image_by_title_safe(article_title, static_dir)
        if image_from_title and image_from_title.get('exists'):
            logger.info(f"‚úÖ Imagen encontrada por t√≠tulo: {image_from_title.get('filename', 'N/A')}")
            return build_image_response(image_from_title, article_title, 'title_pattern', app_context)
        
        # M√âTODO 4: Fallback
        logger.warning(f"‚ö†Ô∏è No se encontr√≥ imagen espec√≠fica para: {article_title}")
        return get_fallback_image(article_title, app_context)
        
    except Exception as e:
        logger.error(f"Error buscando imagen: {e}")
        return get_fallback_image(article_data.get('title', 'Art√≠culo'), app_context)

def find_image_by_metadata_safe(article_data, static_dir):
    """Buscar imagen usando archivos de metadata"""
    try:
        article_title = article_data.get('title', '')
        filename = article_data.get('filename', '')
        
        metadata_files = list(static_dir.glob('*_metadata.json'))
        
        for metadata_file in metadata_files:
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                metadata_title = metadata.get('article_title', '')
                metadata_article_file = metadata.get('article_file', '')
                image_filename = metadata.get('image_filename', '')
                
                # Verificar coincidencia exacta por t√≠tulo
                if metadata_title and article_title and metadata_title.strip().lower() == article_title.strip().lower():
                    image_path = static_dir / image_filename
                    if image_path.exists():
                        logger.info(f"üìã Coincidencia por t√≠tulo en metadata: {metadata_file.name}")
                        return {
                            "image_path": image_path,
                            "filename": image_filename,
                            "exists": True,
                            "metadata": metadata
                        }
                
                # Verificar coincidencia por archivo
                if metadata_article_file and filename and metadata_article_file in filename:
                    image_path = static_dir / image_filename
                    if image_path.exists():
                        logger.info(f"üìã Coincidencia por archivo en metadata: {metadata_file.name}")
                        return {
                            "image_path": image_path,
                            "filename": image_filename,
                            "exists": True,
                            "metadata": metadata
                        }
                        
            except Exception as e:
                logger.error(f"Error leyendo metadata {metadata_file}: {e}")
        
        return None
        
    except Exception as e:
        logger.error(f"Error en find_image_by_metadata_safe: {e}")
        return None

def find_image_by_run_id_safe(run_id, static_dir):
    """Buscar imagen por run_id exacto"""
    try:
        png_files = list(static_dir.glob('*.png'))
        
        for png_file in png_files:
            png_name = png_file.stem.lower()
            run_id_clean = run_id.lower().replace('.json', '')
            
            # Verificar coincidencia exacta del run_id
            if run_id_clean in png_name or png_name in run_id_clean:
                # Verificar que sea una coincidencia significativa
                if len(run_id_clean) > 10 and run_id_clean[:15] in png_name:
                    logger.info(f"üÜî Coincidencia por run_id: {png_file.name}")
                    return {
                        "image_path": png_file,
                        "filename": png_file.name,
                        "exists": True
                    }
        
        return None
        
    except Exception as e:
        logger.error(f"Error en find_image_by_run_id_safe: {e}")
        return None

def find_image_by_title_safe(article_title, static_dir):
    """Buscar imagen por t√≠tulo del art√≠culo"""
    try:
        # Limpiar t√≠tulo para comparaci√≥n
        title_clean = article_title.lower()
        for char in [':', '?', '¬ø', '¬°', '!', '"', "'", ',', '.', ';', '(', ')', '[', ']', '{', '}']:
            title_clean = title_clean.replace(char, '')
        
        # Generar patrones de b√∫squeda m√°s espec√≠ficos
        words = title_clean.split()
        if len(words) >= 3:
            # Usar las primeras 3-4 palabras para mayor precisi√≥n
            pattern_words = words[:4]
        else:
            pattern_words = words
        
        patterns = [
            '_'.join(pattern_words),
            '-'.join(pattern_words),
            ''.join(pattern_words),
        ]
        
        # Solo usar patrones suficientemente largos
        patterns = [p for p in patterns if len(p) > 8]
        
        png_files = list(static_dir.glob('*.png'))
        
        for png_file in png_files:
            png_name = png_file.stem.lower()
            
            for pattern in patterns:
                # Verificar coincidencia significativa
                if len(pattern) > 8 and pattern in png_name:
                    logger.info(f"üìù Coincidencia por t√≠tulo: {png_file.name} (patr√≥n: {pattern})")
                    return {
                        "image_path": png_file,
                        "filename": png_file.name,
                        "exists": True
                    }
        
        return None
        
    except Exception as e:
        logger.error(f"Error en find_image_by_title_safe: {e}")
        return None

def build_image_response(image_data, article_title, source, app_context=None):
    """Construir respuesta de imagen de forma segura"""
    try:
        if not image_data or not image_data.get('exists', False):
            logger.warning(f"‚ö†Ô∏è Imagen no existe para: {article_title}")
            return get_fallback_image(article_title, app_context)
        
        filename = image_data.get('filename', '')
        if filename:
            try:
                # Intentar construir URL con url_for
                if app_context:
                    with app_context:
                        web_path = url_for('static', filename=f'seo_images/{filename}')
                else:
                    # Fallback a ruta manual
                    web_path = f'/static/seo_images/{filename}'
                
                return {
                    "original_path": image_data.get('original_path', ''),
                    "web_path": web_path,
                    "article_title": article_title,
                    "timestamp": datetime.now().isoformat(),
                    "exists": True,
                    "is_fallback": False,
                    "source": source,
                    "filename": filename
                }
                
            except Exception as url_error:
                logger.error(f"‚ùå Error construyendo URL para imagen: {url_error}")
                # Usar ruta manual como fallback
                web_path = f'/static/seo_images/{filename}'
                
                return {
                    "original_path": image_data.get('original_path', ''),
                    "web_path": web_path,
                    "article_title": article_title,
                    "timestamp": datetime.now().isoformat(),
                    "exists": True,
                    "is_fallback": False,
                    "source": source,
                    "filename": filename
                }
        else:
            logger.warning(f"‚ö†Ô∏è No hay filename para imagen de: {article_title}")
            return get_fallback_image(article_title, app_context)
            
    except Exception as e:
        logger.error(f"‚ùå Error construyendo respuesta de imagen: {e}")
        return get_fallback_image(article_title, app_context)

def get_fallback_image(article_title, app_context=None):
    """Obtener imagen por defecto del sistema"""
    create_default_image()
    
    try:
        # Si tenemos contexto de aplicaci√≥n, usar url_for
        if app_context:
            with app_context:
                web_path = url_for('static', filename='images/default-article.png')
        else:
            # Sin contexto, construir URL manualmente
            web_path = '/static/images/default-article.png'
        
        return {
            "original_path": "",
            "web_path": web_path,
            "article_title": article_title,
            "timestamp": datetime.now().isoformat(),
            "exists": False,
            "is_fallback": True,
            "source": "fallback"
        }
    except Exception as e:
        logger.error(f"Error en get_fallback_image: {e}")
        return {
            "original_path": "",
            "web_path": "/static/images/default-article.png",
            "article_title": article_title,
            "timestamp": datetime.now().isoformat(),
            "exists": False,
            "is_fallback": True,
            "source": "fallback"
        }

def should_execute_seo():
    """Verificar si debe ejecutarse el flujo SEO - VERSI√ìN CORREGIDA"""
    global last_seo_execution, last_check_time
    
    # ‚úÖ EVITAR VERIFICACIONES CONSTANTES
    current_time = datetime.now()
    
    # Si acabamos de verificar (√∫ltimos 5 minutos), no verificar de nuevo
    if last_check_time and (current_time - last_check_time) < timedelta(minutes=5):
        return False
    
    last_check_time = current_time
    
    # Si nunca se ha ejecutado, ejecutar una vez
    if last_seo_execution is None:
        logger.info("üîÑ Primera ejecuci√≥n SEO programada")
        return True
    
    # Verificar si han pasado 12 horas
    time_since_last = current_time - last_seo_execution
    should_run = time_since_last >= seo_execution_interval
    
    if should_run:
        logger.info(f"üîÑ Han pasado {time_since_last.total_seconds()/3600:.1f} horas desde la √∫ltima ejecuci√≥n SEO")
    else:
        remaining_time = seo_execution_interval - time_since_last
        logger.info(f"‚è≥ Faltan {remaining_time.total_seconds()/3600:.1f} horas para pr√≥xima ejecuci√≥n SEO")
    
    return should_run

def check_and_run_seo():
    """Verificar y ejecutar SEO si es necesario - VERSI√ìN CORREGIDA"""
    global auto_seo_enabled, last_seo_execution  # ‚úÖ Asegurar que la variable est√© declarada
    
    if not auto_seo_enabled:
        return
    
    try:
        current_time = datetime.now()
        
        if should_execute_seo():
            logger.info("üöÄ INICIANDO ejecuci√≥n autom√°tica del flujo SEO")
            logger.info(f"‚è∞ Hora actual: {current_time.strftime('%H:%M:%S')}")
            logger.info(f"üìÖ Fecha: {current_time.strftime('%Y-%m-%d')}")
            threading.Thread(target=execute_seo_workflow, daemon=True).start()
        else:
            # ‚úÖ CORRECCI√ìN: Cambiar "last_seeo_execution" por "last_seo_execution"
            if last_seo_execution:
                time_until_next = seo_execution_interval - (current_time - last_seo_execution)  # ‚úÖ CORREGIDO
                hours_remaining = time_until_next.total_seconds() / 3600
                
                # Solo loggear si faltan menos de 1 hora o es un intervalo espec√≠fico
                if hours_remaining < 1 or current_time.minute in [0, 30]:
                    logger.info(f"‚è≥ Pr√≥xima ejecuci√≥n SEO en: {hours_remaining:.1f} horas")
            else:
                logger.info("‚è≥ Primera ejecuci√≥n SEO pendiente")
                
    except Exception as e:
        logger.error(f"‚ùå Error en check_and_run_seo: {e}")

def execute_seo_workflow():
    """Ejecutar el flujo de trabajo SEO en segundo plano - VERSI√ìN √öNICA"""
    global last_seo_execution
    
    with seo_lock:
        try:
            start_time = datetime.now()
            logger.info(f"üöÄ INICIO ejecuci√≥n SEO - {start_time.strftime('%H:%M:%S')}")
            
            paths = get_seo_paths()
            workflow_script = paths['workflow_script']
            
            if not workflow_script.exists():
                logger.error(f"‚ùå Script SEO no encontrado: {workflow_script}")
                return False
            
            for dir_path in [paths['output_dir'], paths['articulos_dir'], 
                           paths['seo_json_dir'], paths['static_dir'], paths['results_dir']]:
                dir_path.mkdir(parents=True, exist_ok=True)
            
            logger.info("üìã Ejecutando script SEO...")
            
            result = subprocess.run([
                sys.executable, str(workflow_script)
            ], capture_output=True, text=True, timeout=1800)
            
            end_time = datetime.now()
            duration = end_time - start_time
            
            if result.returncode == 0:
                logger.info(f"‚úÖ Flujo SEO completado exitosamente en {duration.total_seconds():.1f}s")
                logger.info(f"üïê Finalizado a las: {end_time.strftime('%H:%M:%S')}")
                last_seo_execution = end_time
                update_results_files()
                
                # Log de pr√≥xima ejecuci√≥n
                next_execution = last_seo_execution + seo_execution_interval
                logger.info(f"‚è∞ Pr√≥xima ejecuci√≥n programada: {next_execution.strftime('%H:%M:%S')}")
                
                return True
            else:
                logger.error(f"‚ùå Error ejecutando flujo SEO: {result.stderr}")
                logger.info(f"üìã Salida del script: {result.stdout}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.error("‚è∞ Timeout ejecutando flujo SEO (30 minutos)")
            return False
        except Exception as e:
            logger.error(f"üí• Excepci√≥n ejecutando flujo SEO: {e}")
            return False

def update_results_files():
    """Actualizar archivos de resultados agregando los nuevos art√≠culos"""
    try:
        paths = get_seo_paths()
        articulos_dir = paths['articulos_dir']
        static_dir = paths['static_dir']
        latest_articles_file = paths['latest_articles']
        latest_results_file = paths['latest_results']
        
        existing_results = []
        if latest_results_file.exists():
            try:
                with open(latest_results_file, 'r', encoding='utf-8') as f:
                    existing_results = json.load(f)
            except Exception as e:
                logger.error(f"Error cargando resultados existentes: {e}")
        
        new_articles = []
        if articulos_dir.exists():
            for article_file in articulos_dir.glob('*.json'):
                try:
                    with open(article_file, 'r', encoding='utf-8') as f:
                        article_data = json.load(f)
                    
                    run_id = article_file.stem
                    
                    # Agregar informaci√≥n adicional para b√∫squeda de imagen
                    article_data['filename'] = article_file.name
                    article_data['run_id'] = run_id
                    
                    # Buscar imagen espec√≠fica para este art√≠culo SIN contexto Flask
                    image_data = find_corresponding_image(article_data, static_dir, app_context=None)
                    
                    result_entry = {
                        "run_id": run_id,
                        "article": article_data,
                        "image": image_data,
                        "timestamp": article_data.get('generated_at', datetime.now().isoformat())
                    }
                    
                    if not any(r.get('run_id') == run_id for r in existing_results):
                        new_articles.append(result_entry)
                        logger.info(f"‚ûï Nuevo art√≠culo agregado: {run_id}")
                        logger.info(f"   üñºÔ∏è Imagen: {image_data.get('source', 'N/A')} - {image_data.get('web_path', 'N/A')}")
                        
                except Exception as e:
                    logger.error(f"Error procesando art√≠culo {article_file}: {e}")
        
        all_results = new_articles + existing_results
        all_results.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        all_results = all_results[:20]
        
        with open(latest_results_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2)
        
        latest_6 = all_results[:6]
        with open(latest_articles_file, 'w', encoding='utf-8') as f:
            json.dump(latest_6, f, ensure_ascii=False, indent=2)
        
        logger.info(f"üìù Actualizados archivos de resultados: {len(new_articles)} nuevos art√≠culos")
        
    except Exception as e:
        logger.error(f"Error actualizando archivos de resultados: {e}")

# ‚úÖ REEMPLAZAR LA FUNCI√ìN DUPLICADA CON ESTA VERSI√ìN √öNICA
def load_articles_from_latest_results():
    """Cargar art√≠culos desde latest_results.json - VERSI√ìN CORREGIDA"""
    try:
        paths = get_seo_paths()
        latest_results_file = paths['latest_results']
        
        logger.info(f"üìÇ Cargando art√≠culos desde: {latest_results_file}")
        
        if not latest_results_file.exists():
            logger.warning(f"‚ö†Ô∏è Archivo no existe: {latest_results_file}")
            return []
        
        # Leer archivo JSON
        with open(latest_results_file, 'r', encoding='utf-8') as f:
            results_data = json.load(f)
        
        if not results_data:
            logger.warning("‚ö†Ô∏è No hay datos en latest_results.json")
            return []
        
        logger.info(f"üìÑ Encontrados {len(results_data)} resultados en el archivo")
        
        # Procesar art√≠culos - ‚úÖ SOLO LOS √öLTIMOS 6
        articles = []
        for i, result in enumerate(results_data[:6]):  # ‚úÖ SOLO LOS PRIMEROS 6
            try:
                # Extraer datos del art√≠culo
                article_data = result.get('article', {})
                image_data = result.get('image', {})
                
                # ‚úÖ VERIFICAR QUE TENGA T√çTULO
                title = article_data.get('title', '')
                if not title:
                    logger.warning(f"‚ö†Ô∏è Art√≠culo {i+1} sin t√≠tulo, saltando...")
                    continue
                
                # ‚úÖ CREAR OBJETO ART√çCULO PROCESADO COMO DICCIONARIO
                processed_article = {
                    'title': title,
                    'content': article_data.get('content', ''),
                    'excerpt': article_data.get('content', '')[:300] + '...' if len(article_data.get('content', '')) > 300 else article_data.get('content', ''),
                    'meta_description': article_data.get('meta_description', ''),
                    'keywords': article_data.get('keywords', []),
                    'references': article_data.get('references', []),
                    'generated_at': article_data.get('generated_at', datetime.now().isoformat()),
                    'run_id': result.get('run_id', ''),
                    'filename': article_data.get('filename', ''),
                    'source_topics': article_data.get('source_topics', []),
                    'model_used': article_data.get('model_used', 'llama3-70b-8192'),
                    
                    # Datos de imagen
                    'image_path': image_data.get('web_path', '/static/images/default-article.png'),
                    'image_exists': image_data.get('exists', False),
                    'image_filename': image_data.get('filename', ''),
                    'has_image': image_data.get('exists', False),
                    
                    # Timestamp para ordenar
                    'timestamp': result.get('timestamp', datetime.now().isoformat())
                }
                
                articles.append(processed_article)
                logger.debug(f"‚úÖ Procesado art√≠culo: {processed_article['title'][:50]}...")
                
            except Exception as e:
                logger.error(f"‚ùå Error procesando art√≠culo {i+1}: {e}")
                continue
        
        logger.info(f"‚úÖ Procesados {len(articles)} art√≠culos exitosamente")
        
        # Ordenar por fecha (m√°s recientes primero)
        articles.sort(key=lambda x: x['timestamp'], reverse=True)
        
        return articles
        
    except Exception as e:
        logger.error(f"‚ùå Error cargando art√≠culos: {e}")
        import traceback
        logger.error(f"üìã Traceback: {traceback.format_exc()}")
        return []

@news_bp.route('/noticias')
def noticias():
    """P√°gina principal de noticias - VERSI√ìN CORREGIDA FINAL"""
    try:
        logger.info("üì∞ Cargando p√°gina de noticias...")
        
        # Verificar y ejecutar SEO si es necesario
        check_and_run_seo()
        
        # ‚úÖ CARGAR ART√çCULOS DESDE latest_results.json (SOLO LOS √öLTIMOS 6)
        articles = load_articles_from_latest_results()
        
        if not articles:
            logger.warning("‚ö†Ô∏è No se encontraron art√≠culos")
            return render_template('noticias.html',
                                 articles=[],
                                 current_time=datetime.now(),
                                 total_articles=0,
                                 error_message="No hay art√≠culos disponibles en este momento.")
        
        logger.info(f"üì∞ Mostrando {len(articles)} art√≠culos en la p√°gina")
        
        return render_template('noticias.html',
                             articles=articles,
                             current_time=datetime.now(),
                             total_articles=len(articles))
        
    except Exception as e:
        logger.error(f"‚ùå Error en ruta noticias: {e}")
        import traceback
        logger.error(f"üìã Traceback: {traceback.format_exc()}")
        
        return render_template('noticias.html',
                             articles=[],
                             current_time=datetime.now(),
                             total_articles=0,
                             error_message="Error cargando noticias. Por favor, intenta m√°s tarde.")

@news_bp.route('/articulo/<article_id>')
def ver_articulo(article_id):
    """Ver un art√≠culo espec√≠fico - VERSI√ìN CORREGIDA"""
    try:
        logger.info(f"üìñ Solicitando art√≠culo: {article_id}")
        
        # Cargar todos los art√≠culos desde latest_results.json
        articles = load_articles_from_latest_results()
        
        if not articles:
            logger.warning("‚ö†Ô∏è No se encontraron art√≠culos")
            abort(404)
        
        # Buscar el art√≠culo espec√≠fico por run_id
        article_data = None
        for art in articles:
            if art.get('run_id') == article_id:
                article_data = art
                break
        
        if not article_data:
            logger.warning(f"‚ö†Ô∏è Art√≠culo no encontrado: {article_id}")
            abort(404)
        
        logger.info(f"‚úÖ Art√≠culo encontrado: {article_data.get('title', 'Sin t√≠tulo')}")
        
        # ‚úÖ RESTRUCTURAR DATOS PARA EL TEMPLATE
        article_for_template = {
            'article': {
                'title': article_data.get('title', ''),
                'content': article_data.get('content', ''),
                'meta_description': article_data.get('meta_description', ''),
                'keywords': article_data.get('keywords', []),
                'references': article_data.get('references', []),
                'generated_at': article_data.get('generated_at', '')
            },
            'image': {
                'web_path': article_data.get('image_path', '/static/images/default-article.png'),
                'timestamp': article_data.get('timestamp', ''),
                'exists': article_data.get('image_exists', False)
            },
            'run_id': article_data.get('run_id', '')
        }
        
        # ‚úÖ RENDERIZAR CON ESTRUCTURA CORRECTA
        return render_template('public_article.html', 
                             article=article_for_template,
                             current_time=datetime.now())
        
    except Exception as e:
        logger.error(f"‚ùå Error cargando art√≠culo {article_id}: {e}")
        abort(500)

@news_bp.route('/api/noticias')
def api_noticias():
    """API para obtener noticias en formato JSON"""
    try:
        articles = load_articles_from_latest_results()
        
        return jsonify({
            'success': True,
            'total': len(articles),
            'articles': articles  # Todos los art√≠culos (m√°ximo 6)
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error en API noticias: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'articles': []
        }), 500

# ‚úÖ RUTA PARA SERVIR IM√ÅGENES SEO
@news_bp.route('/static/seo_images/<filename>')
def serve_seo_image(filename):
    """Servir im√°genes SEO generadas"""
    try:
        paths = get_seo_paths()
        static_dir = paths['static_dir']
        
        image_path = static_dir / filename
        
        if not image_path.exists():
            logger.warning(f"‚ö†Ô∏è Imagen SEO no encontrada: {filename}")
            # Retornar imagen por defecto
            default_image = Path(__file__).parent.parent / 'static' / 'images' / 'default-article.png'
            if default_image.exists():
                return send_from_directory(str(default_image.parent), 'default-article.png')
            else:
                abort(404)
        
        logger.info(f"üñºÔ∏è Sirviendo imagen SEO: {filename}")
        return send_from_directory(str(static_dir), filename)
        
    except Exception as e:
        logger.error(f"‚ùå Error sirviendo imagen SEO {filename}: {e}")
        abort(500)